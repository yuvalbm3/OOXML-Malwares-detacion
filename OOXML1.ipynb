{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mal_zip = '/home/kali/Downloads/OOXML/virus_zip'\n",
    "mal_fol = '/home/kali/Downloads/OOXML/virus_folder'\n",
    "ben = '/home/kali/Downloads/OOXML/www.chabas.gob.ar_index.php_descargas_category_12-2017-2019_download=306_ordenanza-1165'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4692550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suspicios words\n",
    "\n",
    "susword = ['0x', 'base64 strings', 'auroopen', 'shell', 'chr', 'run', 'showwindow', 'document_open',\n",
    "               'creatobject', 'chrw', 'vba_stomping', 'call', 'chrb', 'vbhide', 'wscript.shell', 'strreverse', 'xor',\n",
    "               'dridex_strings', 'open', 'system']\n",
    "\n",
    "def SusWords(path):\n",
    "\n",
    "    x=\"\"\n",
    "    try:\n",
    "        fol = os.listdir(path)\n",
    "        for i in fol:\n",
    "            if i.endswith(\"xml\"):\n",
    "                try:\n",
    "                    f = open(f'{path}/{i}', 'r', encoding='utf-8')\n",
    "                    x=x+f.read()\n",
    "                except:\n",
    "                    print(f'!!!{path}/{i}')\n",
    "            elif len(i) > 2:\n",
    "                SusWords(f'{path}/{i}')\n",
    "#this file isn't folder\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    i = 0\n",
    "    for word in susword:\n",
    "        i = i + x.count(word)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read xml and count word,line,pages, and times\n",
    "def AppAndCore(path):\n",
    "    x1,y1,z1,w1=\"\",\"\",\"\",\"\"\n",
    "    arr=[-1,-1,-1,-1,-1]\n",
    "    try:\n",
    "        tree = ET.parse(f'{path}/docProps/app.xml')\n",
    "        root = tree.getroot()\n",
    "        for i in tree.getroot():\n",
    "            if \"Words\" in i.tag:\n",
    "                arr[0]=(int(i.text))\n",
    "            if \"Lines\" in i.tag:\n",
    "                arr[1]=(int(i.text))\n",
    "            if \"Pages\" in i.tag:\n",
    "                arr[2]=(int(i.text))\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        # models = file.getElementsByTagName('Lines')\n",
    "        # print(models.value)\n",
    "        #\n",
    "        datetime_object1 = datetime.now()\n",
    "        datetime_object2 = datetime.now()\n",
    "        tree1 = ET.parse(f'{path}/docProps/core.xml')\n",
    "        for i in tree1.getroot():\n",
    "\n",
    "            if \"created\" in i.tag:\n",
    "                arr[3]=((i.text))\n",
    "                y=str(i.text).split('T')\n",
    "                z=y[0]+\" \"+y[1][:-1]\n",
    "                datetime_object1 = datetime.strptime(z, '%Y-%m-%d %H:%M:%S')\n",
    "            if \"modified\" in i.tag:\n",
    "                arr[4]=(i.text)\n",
    "                y1=str(i.text).split('T')\n",
    "                z1=y1[0]+\" \"+y[1][:-1]\n",
    "                datetime_object2 = datetime.strptime(z1, '%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        return arr\n",
    "        \n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a983a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check size of embedded folder\n",
    "def embedded_size(path):\n",
    "    fol = os.listdir(path)\n",
    "    size = 0\n",
    "    if 'Embedding' in fol:\n",
    "        path1 = f'{path}/word/Embedding'\n",
    "        fol1 = os.listdir(path1)\n",
    "        for i in fol1:\n",
    "            size = os.path.getsize(f'{path1}/{i}')\n",
    "    return (size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b25abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many modify were\n",
    "def CountRSID(path):\n",
    "    try:\n",
    "        with open(f'{path}/word/settings.xml') as file:\n",
    "            z=file.read()\n",
    "            return (z.count(\"w:rsid w:val\"))\n",
    "    except:\n",
    "        return -1\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419158b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the data frame\n",
    "fol_mal = os.listdir(mal_fol)\n",
    "fol_ben = os.listdir(ben)\n",
    "\n",
    "j=0\n",
    "arr=[]\n",
    "\n",
    "for i in fol_ben:\n",
    "    temparr=[]\n",
    "    temparr.append(i)\n",
    "    temparr.append(CountRSID(f'{ben}/{i}'))\n",
    "    temparr.append(SusWords(f'{ben}/{i}'))\n",
    "    temparr=temparr+AppAndCore(f'{ben}/{i}')\n",
    "    temparr.append(embedded_size(f'{ben}/{i}'))\n",
    "    temparr.append('Benign')\n",
    "    arr.append(temparr)\n",
    "    if j==0:\n",
    "        print(arr)\n",
    "        j=1\n",
    "# Import pandas library\n",
    "# print(arr)\n",
    "# initialize list of lists\n",
    "for i in fol_mal:\n",
    "    temparr=[]\n",
    "    temparr.append(i)\n",
    "    temparr.append(CountRSID(f'{mal_fol}/{i}'))\n",
    "    temparr.append(SusWords(f'{mal_fol}/{i}'))\n",
    "    temparr=temparr+AppAndCore(f'{mal_fol}/{i}')\n",
    "    temparr.append(embedded_size(f'{mal_fol}/{i}'))\n",
    "    temparr.append('Malware')\n",
    "    arr.append(temparr)\n",
    "    if j==0:\n",
    "        print(arr)\n",
    "        j=1\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(arr, columns=[\"Name\",'RSID', 'SUSWORDS','Words','Lines','Pages','Created','Modified','Embedding','label'])\n",
    "\n",
    "# print dataframe.\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Embedding\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418841b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfff634",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = df.columns.to_list()\n",
    "features_list.remove('label')\n",
    "features_list.remove('Name')\n",
    "features_list.remove('Created')\n",
    "features_list.remove('Modified')\n",
    "\n",
    "X = df[features_list].to_numpy()\n",
    "\n",
    "# This column is the desired prediction we will train our model on\n",
    "y = np.stack(df['label'])\n",
    "\n",
    "# We split the dataset to train and test according to the required ration\n",
    "# Do not change the test_size -> you can change anything else\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1765, random_state=10, stratify=y)\n",
    "# We print the resulted datasets and count the difference \n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c834c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We choose our model of choice and set it's hyper parameters you can change anything\n",
    "clf =RandomForestClassifier(n_estimators=100, random_state=10)\n",
    "\n",
    "# Train Model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check data balance and variety\n",
    "print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b748914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We print our results\n",
    "\n",
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "predictions = clf.predict(X_test)\n",
    "true_labels = y_test\n",
    "cf_matrix = confusion_matrix(true_labels, predictions)\n",
    "clf_report = classification_report(true_labels, predictions, digits=10)\n",
    "heatmap = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='g', \n",
    "                      xticklabels=np.unique(true_labels), \n",
    "                      yticklabels=np.unique(true_labels)) \n",
    "\n",
    "# The heatmap is cool but this is the most important result\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df1703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33d3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8599bcd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8bebbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
